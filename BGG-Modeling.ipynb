{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train = pd.read_pickle('data/train_df.pkl')\n",
    "test = pd.read_pickle('data/test_df.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['Abstract', \"Children's\", 'Family', 'Strategy', 'Thematic', 'Wargames']\n"
     ]
    }
   ],
   "source": [
    "cols = list(train.columns.values)\n",
    "genre_cols = cols[-6:]\n",
    "print(len(genre_cols))\n",
    "print(genre_cols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_train = train[train.columns[~train.columns.isin(genre_cols)]]\n",
    "y_train = train[train.columns[ train.columns.isin(genre_cols)]]\n",
    "\n",
    "X_test = test[test.columns[~test.columns.isin(genre_cols)]]\n",
    "y_test = test[test.columns[ test.columns.isin(genre_cols)]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['data/scaler.pkl']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "my_standard_scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = my_standard_scaler.transform(X_train)\n",
    "X_test_s = my_standard_scaler.transform(X_test)\n",
    "\n",
    "joblib.dump(my_standard_scaler, 'data/scaler.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65335753 0.65263158 0.63798112 0.65395788 0.65686275]\n",
      "Fold 1: 0.6533575317604355\n",
      "Fold 2: 0.6526315789473685\n",
      "Fold 3: 0.6379811183732752\n",
      "Fold 4: 0.6539578794480755\n",
      "Fold 5: 0.6568627450980392\n",
      "Average Score:0.6509581707254387\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "my_log_model = OneVsRestClassifier(LogisticRegression(random_state=123, solver='lbfgs', max_iter=3000, C=0.01, n_jobs=-1), n_jobs=-1)\n",
    "\n",
    "scores = cross_val_score(my_log_model, X_train_s, y_train, cv = 5)\n",
    "print(scores)\n",
    "\n",
    "for i in range(len(scores)) :\n",
    "    print(f\"Fold {i+1}: {scores[i]}\")\n",
    "print(f\"Average Score:{np.mean(scores)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "my_log_model = OneVsRestClassifier(LogisticRegression(random_state=42, solver='lbfgs', max_iter=3000, C=0.01, n_jobs=-1), n_jobs=-1).fit(X_train_s, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "y_train_pred = my_log_model.predict(X_train_s)\n",
    "y_train_proba = my_log_model.predict_proba(X_train_s)\n",
    "y_test_pred = my_log_model.predict(X_test_s)\n",
    "y_test_proba = my_log_model.predict_proba(X_test_s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.99332\n",
      "    Test score: 0.64496\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(f'Training score: {accuracy_score(y_train, y_train_pred):0.5f}')\n",
    "print(f'    Test score: {accuracy_score(y_test, y_test_pred):0.5f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9072  Abstract\n",
      "0.9203  Children's\n",
      "0.8647  Family\n",
      "0.9090  Strategy\n",
      "0.9386  Thematic\n",
      "0.9591  Wargames\n"
     ]
    }
   ],
   "source": [
    "y_pred_df = pd.DataFrame(y_test_pred, columns=genre_cols)\n",
    "\n",
    "# Test set predictions\n",
    "for g in genre_cols:\n",
    "    score = accuracy_score(y_test[g], y_pred_df[g])\n",
    "    print(f'{score:0.4f}  {g}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80      1096\n",
      "           1       0.84      0.78      0.81       990\n",
      "           2       0.48      0.43      0.45       596\n",
      "           3       0.75      0.61      0.67       699\n",
      "           4       0.64      0.49      0.56       359\n",
      "           5       0.94      0.90      0.92      1231\n",
      "\n",
      "   micro avg       0.80      0.72      0.76      4971\n",
      "   macro avg       0.74      0.66      0.70      4971\n",
      "weighted avg       0.79      0.72      0.75      4971\n",
      " samples avg       0.73      0.75      0.73      4971\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred_df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4.87273445e-04, 4.69049621e-04, 4.17110538e-01, 8.15159215e-05,\n        3.26383364e-04, 9.70374924e-01],\n       [4.68053096e-01, 4.57538935e-01, 2.96710033e-02, 8.12611170e-05,\n        2.65019157e-04, 3.81127815e-01],\n       [3.20335912e-05, 8.55501500e-05, 3.18898002e-01, 9.99993935e-01,\n        1.89086289e-03, 4.44569180e-04],\n       ...,\n       [9.94382525e-01, 4.58926277e-04, 8.09390619e-02, 1.12788407e-03,\n        1.06607169e-03, 1.55441895e-03],\n       [9.68680690e-01, 9.96152012e-02, 6.00175457e-05, 6.90522019e-04,\n        6.36489901e-07, 5.51254774e-03],\n       [2.17251411e-05, 6.95235108e-02, 9.30828934e-01, 1.54215375e-02,\n        9.81727958e-01, 8.19274429e-05]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_proba"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "       Abstract  Children's  Family  Strategy  Thematic  Wargames\n11809         0           0       0         0         0         1\n3993          0           1       0         0         0         0\n7834          0           0       0         1         0         0\n4708          0           1       0         0         0         0\n2993          0           1       0         0         0         0\n...         ...         ...     ...       ...       ...       ...\n13266         0           0       0         0         0         1\n11859         0           0       0         0         0         1\n16534         1           0       0         0         0         0\n15123         1           0       0         0         0         0\n33            0           0       0         0         1         0\n\n[4591 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Abstract</th>\n      <th>Children's</th>\n      <th>Family</th>\n      <th>Strategy</th>\n      <th>Thematic</th>\n      <th>Wargames</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11809</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3993</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7834</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4708</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2993</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13266</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11859</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16534</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15123</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4591 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "my_tfidf = joblib.load('data/my_tfidf_min10.pkl')\n",
    "my_scaler = joblib.load('data/scaler.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "my_string = \"Theme Players take the part of land owners, attempting to buy and then develop their land. Income is gained by other players visiting their properties and money is spent when they visit properties belonging to other players. When times get tough, players may have to mortgage their properties to raise cash for fines, taxes and other misfortunes. Gameplay On his turn, a player rolls two dice and moves that number of spaces around the board. If the player lands on an as-yet-unowned property, he has the opportunity to buy it and add it to his portfolio or allow the bank to auction it to the highest bidder. If a player owns all the spaces within a color group, he may then build houses and hotels on these spaces, generating even more income from opponents who land there. If he lands on a property owned by another player, he must pay that player rent according to the value of the land and any buildings on it. There are other places on the board which can not be bought, but instead require the player to draw a card and perform the action on the card, pay taxes, collect income, or even go to jail. Goal The goal of the game is to be the last player remaining with any money. Cultural impact on rules Monopoly is unusual in that the game has official, printed rules, but most players learn how to play from others, never actually learning the correct way to play. This has led to the canonization of a number of house rules that make the game more palatable to children (and sore losers) but harm the gameplay by preventing players from going bankrupt or slowing down the rate of property acquisition. One common house rule has players put any money paid to the bank in the center of the board, which jackpot a player may earn by landing on Free Parking. This prevents the game from removing money from play, and since players collect $200 each time they pass Go, this results in ever-increasing bankrolls and players surviving rents that should have bankrupted them. Another house rule allows players to take loans from the bank instead of going bankrupt, which means the game will never end. Some house rules arise out of ignorance rather than attempts to improve the game. For instance, many players don't know that properties landed on but left unbought go up for auction, and even some that know to auction don't know that the bidding starts at $1, meaning a player may pay well below the listed price for an auctioned property. Background In the USA in 1933, Charles Darrow devised Monopoly based on an earlier game by Elizabeth J. Magie. The patent was filed 31st August 1935 while the game was on sale in America. Based on an earlier game, The Landlord's Game, it was at first rejected by Parker Bros., as being too complicated to be a success. How wrong could they be! It came to the UK in 1936, made under licence by Waddingtons. Darrow died in 1967 having realised he had developed one of the most successful board games of all times. It was awarded as Game of the Century by the TRA (Toy Retailers Association). Monopoly was patented in 1935 by Charles Darrow and released by Parker Brothers. The game was actually one of a number of variants in existence at the time, all of which date back to an earlier, 1904 game by Elizabeth J. Magie called The Landlord's Game. Magie was a proponent of the Single Tax put forth by famous author Henry George. The game was designed to show the evils of earning money from renting land (as it leads to the destitution of all but one player) and the virtues of the proposed Single Tax - players could choose to play under regular rules or alternate Single Tax rules. The game didn't really go anywhere and Magie lost interest in it. Variations of the game evolved, however, and homemade versions traveled up and down the Atlantic coast and even as far west as Michigan and Texas, being developed all along the way. Eventually the game was noticed by Charles Darrow, who introduced it to the world in its current form.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def clean_desc(raw_html):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \",raw_html)\n",
    "    clean = ' '.join(clean.split())\n",
    "    clean = clean.lower()\n",
    "    return clean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "my_string = clean_desc(my_string)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the document\n",
    "    \"\"\"\n",
    "    return word_tokenize(text)\n",
    "\n",
    "#Load up our stop words\n",
    "stop_words = stopwords.words('english')\n",
    "#Adds stuff to our stop words list\n",
    "stop_words.extend(['.',','])\n",
    "\n",
    "## This function can improve, simplify. Look into Text Data Lecture\n",
    "def remove_stopwords(list_of_tokens):\n",
    "    \"\"\"\n",
    "    Removes stopwords\n",
    "    \"\"\"\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token in list_of_tokens:\n",
    "        if token in stop_words: continue\n",
    "        cleaned_tokens.append(token)\n",
    "\n",
    "    return cleaned_tokens\n",
    "\n",
    "def stemmer(list_of_tokens):\n",
    "    '''\n",
    "    Takes in an input which is a list of tokens, and spits out a list of stemmed tokens.\n",
    "    '''\n",
    "\n",
    "    stemmed_tokens_list = []\n",
    "\n",
    "    for i in list_of_tokens:\n",
    "\n",
    "        token = PorterStemmer().stem(i)\n",
    "        stemmed_tokens_list.append(token)\n",
    "\n",
    "    return stemmed_tokens_list\n",
    "\n",
    "def lemmatizer(list_of_tokens):\n",
    "\n",
    "    lemmatized_tokens_list = []\n",
    "\n",
    "    for i in list_of_tokens:\n",
    "        token = WordNetLemmatizer().lemmatize(i)\n",
    "        lemmatized_tokens_list.append(token)\n",
    "\n",
    "    return lemmatized_tokens_list\n",
    "\n",
    "\n",
    "def the_untokenizer(token_list):\n",
    "    '''\n",
    "    Returns all the tokenized words in the list to one string.\n",
    "    Used after the pre processing, such as removing stopwords, and lemmatizing.\n",
    "    '''\n",
    "    return \" \".join(token_list)\n",
    "\n",
    "def clean_string(my_string):\n",
    "    tokenized_list = word_tokenize(my_string)\n",
    "    removed_stopwords = remove_stopwords(tokenized_list)\n",
    "    stemmed_words = stemmer(removed_stopwords)\n",
    "    lemmatized_words = lemmatizer(stemmed_words)\n",
    "    back_to_string = the_untokenizer(lemmatized_words)\n",
    "    return back_to_string"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "input_tfidf = my_tfidf.transform([clean_string(my_string)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "input_transformed_df = pd.DataFrame(input_tfidf.toarray(), columns=my_tfidf.get_feature_names())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "input_final_df = my_scaler.transform(input_transformed_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "input_pred = my_log_model.predict_proba(input_final_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.95593726e-02, 1.55674133e-04, 4.85605699e-01, 3.28340610e-01,\n        1.20203289e-03, 2.08759836e-04]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "['data/my_best_model.pkl']"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(my_log_model, 'data/my_best_model.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<WordListCorpusReader in 'C:\\\\Users\\\\Noah\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords'>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}